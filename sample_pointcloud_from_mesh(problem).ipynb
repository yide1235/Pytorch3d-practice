{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_Ip8kp4TfBLZ"},"outputs":[],"source":["# Copyright (c) Meta Platforms, Inc. and affiliates. All rights reserved."]},{"cell_type":"markdown","metadata":{"id":"kuXHJv44fBLe"},"source":["# Render a textured mesh\n","\n","This tutorial shows how to:\n","- load a mesh and textures from an `.obj` file.\n","- set up a renderer\n","- render the mesh\n","- vary the rendering settings such as lighting and camera position\n","- use the batching features of the pytorch3d API to render the mesh from different viewpoints"]},{"cell_type":"markdown","metadata":{"id":"Bnj3THhzfBLf"},"source":["## 0. Install and Import modules"]},{"cell_type":"markdown","metadata":{"id":"okLalbR_g7NS"},"source":["Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"musUWTglgxSB","executionInfo":{"status":"ok","timestamp":1691641535572,"user_tz":420,"elapsed":1,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}}},"outputs":[],"source":["import os\n","import sys\n","import torch\n","need_pytorch3d=False\n","try:\n","    import pytorch3d\n","except ModuleNotFoundError:\n","    need_pytorch3d=True\n","if need_pytorch3d:\n","    if torch.__version__.startswith((\"1.13.\", \"2.0.\")) and sys.platform.startswith(\"linux\"):\n","        # We try to install PyTorch3D via a released wheel.\n","        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n","        version_str=\"\".join([\n","            f\"py3{sys.version_info.minor}_cu\",\n","            torch.version.cuda.replace(\".\",\"\"),\n","            f\"_pyt{pyt_version_str}\"\n","        ])\n","        !pip install fvcore iopath\n","        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n","    else:\n","        # We try to install PyTorch3D from source.\n","        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"nX99zdoffBLg","executionInfo":{"status":"ok","timestamp":1691641988940,"user_tz":420,"elapsed":1,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}}},"outputs":[],"source":["import os\n","import torch\n","import matplotlib.pyplot as plt\n","\n","# Util function for loading meshes\n","from pytorch3d.io import load_objs_as_meshes, load_obj\n","\n","# Data structures and functions for rendering\n","from pytorch3d.structures import Meshes,Pointclouds\n","from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\n","from pytorch3d.vis.texture_vis import texturesuv_image_matplotlib\n","from pytorch3d.renderer import (\n","    look_at_view_transform,\n","    FoVPerspectiveCameras,\n","    PointLights,\n","    DirectionalLights,\n","    Materials,\n","    RasterizationSettings,\n","    MeshRenderer,\n","    MeshRasterizer,\n","    SoftPhongShader,\n","    TexturesUV,\n","    TexturesVertex\n",")\n","\n","# add path for demo utils functions\n","import sys\n","import os\n","sys.path.append(os.path.abspath(''))"]},{"cell_type":"markdown","metadata":{"id":"Lxmehq6Zhrzv"},"source":["If using **Google Colab**, fetch the utils file for plotting image grids:"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZozr3Pmho-5","outputId":"5c891f9b-6f67-4948-a928-0d83dffe7d2c","executionInfo":{"status":"ok","timestamp":1691642030512,"user_tz":420,"elapsed":3,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-08-10 04:33:49--  https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1608 (1.6K) [text/plain]\n","Saving to: ‘plot_image_grid.py’\n","\n","plot_image_grid.py  100%[===================>]   1.57K  --.-KB/s    in 0.001s  \n","\n","2023-08-10 04:33:49 (1.98 MB/s) - ‘plot_image_grid.py’ saved [1608/1608]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\n","from plot_image_grid import image_grid"]},{"cell_type":"markdown","metadata":{"id":"g4B62MzYiJUM"},"source":["OR if running **locally** uncomment and run the following cell:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"paJ4Im8ahl7O"},"outputs":[],"source":["# from utils import image_grid"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3c5InH8HeDt","executionInfo":{"status":"ok","timestamp":1691641310531,"user_tz":420,"elapsed":4,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}},"outputId":"68bd20c3-471f-4a70-a40b-e319733dfc86"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["plot_image_grid.py  __pycache__  sample_data\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","import os\n","\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxWDdATUHxQH","executionInfo":{"status":"ok","timestamp":1691641332800,"user_tz":420,"elapsed":22272,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}},"outputId":"2b5fbb22-3df3-4dba-c248-e2304f09f244"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3naitLvxIBbW","executionInfo":{"status":"ok","timestamp":1691641767089,"user_tz":420,"elapsed":3,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}},"outputId":"2e8b29b0-e81b-4653-d841-0bc4327a3176"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["1_b.gif\t\t\t      q_5-2.gif\n","2.1.gif\t\t\t      q_5-3.gif\n","3_b.gif\t\t\t      rendering_generic_3d_representations.ipynb\n","data\t\t\t      rendering_parametric_and_implicit.ipynb\n","deform_form.ipynb\t      rendering_point_clouds_from_rgbd.ipynb\n","plotly_rendered_meshes.ipynb  rendering_texture_obj.ipynb\n","q_5-1_pc1.gif\t\t      render_tetrahedron_and_retexturing.ipynb\n","q_5-1_pc2.gif\t\t      render_texture_mesh_and_dolly_zoom.ipynb\n","q_5-1_pc_union.gif\t      sample_pointcloud_from_mesh.ipynb\n"]}]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","  device=torch.device(\"cuda:0\")\n","else:\n","  device=torch.device(\"cpu\")\n","  print(\"gpu is not available\")\n"],"metadata":{"id":"a_yQ9A6FJEbE","executionInfo":{"status":"ok","timestamp":1691641335566,"user_tz":420,"elapsed":3,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPeGJKoR-3Re","executionInfo":{"status":"ok","timestamp":1691641337458,"user_tz":420,"elapsed":3,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}},"outputId":"16154af7-d48c-4075-9a62-25c3f0391fff"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["1_b.gif\t\t\t      q_5-2.gif\n","2.1.gif\t\t\t      q_5-3.gif\n","3_b.gif\t\t\t      rendering_generic_3d_representations.ipynb\n","data\t\t\t      rendering_parametric_and_implicit.ipynb\n","deform_form.ipynb\t      rendering_point_clouds_from_rgbd.ipynb\n","plotly_rendered_meshes.ipynb  rendering_texture_obj.ipynb\n","q_5-1_pc1.gif\t\t      render_tetrahedron_and_retexturing.ipynb\n","q_5-1_pc2.gif\t\t      render_texture_mesh_and_dolly_zoom.ipynb\n","q_5-1_pc_union.gif\t      sample_pointcloud_from_mesh.ipynb\n"]}]},{"cell_type":"code","source":["def get_points_renderer(\n","    image_size=512, device=None, radius=0.01, background_color=(1, 1, 1)\n","):\n","    \"\"\"\n","    Returns a Pytorch3D renderer for point clouds.\n","\n","    Args:\n","        image_size (int): The rendered image size.\n","        device (torch.device): The torch device to use (CPU or GPU). If not specified,\n","            will automatically use GPU if available, otherwise CPU.\n","        radius (float): The radius of the rendered point in NDC.\n","        background_color (tuple): The background color of the rendered image.\n","\n","    Returns:\n","        PointsRenderer.\n","    \"\"\"\n","    if device is None:\n","        if torch.cuda.is_available():\n","            device = torch.device(\"cuda:0\")\n","        else:\n","            device = torch.device(\"cpu\")\n","    raster_settings = PointsRasterizationSettings(image_size=image_size, radius=radius,)\n","    renderer = PointsRenderer(\n","        rasterizer=PointsRasterizer(raster_settings=raster_settings),\n","        compositor=AlphaCompositor(background_color=background_color),\n","    )\n","    return renderer"],"metadata":{"id":"Wq2RutoAr_HE","executionInfo":{"status":"ok","timestamp":1691642153273,"user_tz":420,"elapsed":1,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["import random\n","import math\n","from tqdm.notebook import tqdm\n","from PIL import Image, ImageDraw\n","import imageio\n","import numpy as np\n","\n","\n","def PCD_from_mesh(\n","    image_size=512,\n","    num_frames=100,\n","    duration=3,\n","    device=None,\n","    output_file=\"output/\",\n","):\n","    if device is None:\n","        device = device\n","\n","    verts, faces, aux = load_obj(\"data/cow_mesh/cow.obj\")\n","    faces = faces.verts_idx\n","\n","    # Sample a face with probability proportional to the area of the face\n","    num_triangle = faces.shape[0]\n","    areas = torch.zeros((num_triangle))\n","    for i in range(num_triangle):\n","        v1 = verts[faces[i][0]][:]\n","        v2 = verts[faces[i][1]][:]\n","        v3 = verts[faces[i][2]][:]\n","        areas[i] = abs(0.5 * torch.inner(v1-v2, v1-v3))\n","\n","    weight = areas / sum(areas)\n","\n","    num_samples = 1000 # number of point cloud\n","    sampled_faceidx = []\n","    for i in range(num_samples):\n","      rnd = random.uniform(0, 1)\n","      for j, w in enumerate(weight):\n","          if w<0:\n","              raise ValueError(\"Negative weight encountered.\")\n","          rnd -= w\n","          if rnd < 0:\n","              sampled_faceidx.append(j)\n","              break\n","\n","    print(\"number of samples generated is:\", num_samples)\n","    if num_samples != len(sampled_faceidx): raise ValueError(\"WTF?\")\n","\n","    points = torch.zeros((num_samples,3))\n","    for i in range(num_samples):\n","      idx = sampled_faceidx[i]\n","      p1, p2, p3 = verts[faces[idx][0]][:], verts[faces[idx][1]][:], verts[faces[idx][2]][:]\n","      alpha = random.uniform(0, 1)\n","      alpha2 = random.uniform(0, 1)\n","      alpha1 = 1- math.sqrt(alpha)\n","      v = alpha1 * p1 + (1-alpha1)*alpha2*p2 + (1-alpha1)*(1-alpha2)*p3\n","      points[i] = v\n","\n","    color = (points - points.min()) / (points.max() - points.min())\n","\n","\n","    cow_point_cloud = Pointclouds(\n","        points=[points], features = [color]\n","    )\n","\n","    print(points.shape)\n","    print(color.shape)\n","    print(cow_point_cloud)\n","\n","    renders = []\n","    angles = np.linspace(0,360,num_frames)\n","    for i, angle in enumerate(tqdm(angles)):\n","        R, T = pytorch3d.renderer.look_at_view_transform(dist=5.0, elev=2, azim=angle)\n","        cameras = pytorch3d.renderer.FoVPerspectiveCameras(R=R, T=T, device=device)\n","        renderer = get_points_renderer(image_size=image_size, device=device)\n","        rend = renderer(cow_point_cloud, cameras=cameras)\n","        rend = rend.cpu().numpy()[0, ..., :3]  # (B, H, W, 4) -> (H, W, 3)\n","        renders.append(rend)\n","\n","    images = []\n","    for i, r in enumerate(renders):\n","        image = Image.fromarray((r * 255).astype(np.uint8))\n","        draw = ImageDraw.Draw(image)\n","        draw.text((20, 20), f\"angle: {angles[i]:.2f}\", fill=(0, 0, 255))\n","        images.append(np.array(image))\n","    imageio.mimsave(output_file, images, fps=(num_frames / duration))\n","\n","\n","\n","\n","PCD_from_mesh()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457,"referenced_widgets":["80833380f63c4e668d26045f397fa207","2ac86f89c4454458bf9f14b31b668837","54ecc7c72cc1471fab891a9522d072c1","09504b9761304f22a983b9d84e1a3381","16952c39face4d17a07e2b406efa7e5f","4087164151264becb9b9966819a5f814","c21d1835af464a9d86b26f0c9cd08454","5876606f717e4e2b871befb181e2504e","b7baef410ff5481da512fcd10b38b470","de68737312f143be9f1786f3e43ca4fc","492669478b444403af3bbcad2e2e0818"]},"id":"yXmj81gNrig4","executionInfo":{"status":"error","timestamp":1691644585983,"user_tz":420,"elapsed":53124,"user":{"displayName":"Edward ma","userId":"08484308958806977330"}},"outputId":"7a7ecc6f-813f-4cd1-f16e-049904398fd0"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["number of samples generated is: 1000\n","torch.Size([1000, 3])\n","torch.Size([1000, 3])\n","<pytorch3d.structures.pointclouds.Pointclouds object at 0x7b4f1e757220>\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80833380f63c4e668d26045f397fa207"}},"metadata":{}},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-fd3ef155dd9b>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mPCD_from_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-30-fd3ef155dd9b>\u001b[0m in \u001b[0;36mPCD_from_mesh\u001b[0;34m(image_size, num_frames, duration, device, output_file)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlook_at_view_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mcameras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFoVPerspectiveCameras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_points_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mrend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcow_point_cloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcameras\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcameras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/cameras.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, znear, zfar, aspect_ratio, fov, degrees, R, T, K, device)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# The initializer formats all inputs to torch tensors and broadcasts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;31m# all the inputs to have the same batch dimension where necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0mznear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mznear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dtype, device, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[1;32m    111\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/common/datatypes.py\u001b[0m in \u001b[0;36mmake_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[1;32m     28\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# If cuda but with no index, then the current cuda device is indicated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# In that case, we fix to that device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'type'"]}]}],"metadata":{"accelerator":"GPU","anp_metadata":{"path":"notebooks/render_textured_meshes.ipynb"},"bento_stylesheets":{"bento/extensions/flow/main.css":true,"bento/extensions/kernel_selector/main.css":true,"bento/extensions/kernel_ui/main.css":true,"bento/extensions/new_kernel/main.css":true,"bento/extensions/system_usage/main.css":true,"bento/extensions/theme/main.css":true},"colab":{"provenance":[{"file_id":"https://github.com/facebookresearch/pytorch3d/blob/stable/docs/tutorials/render_textured_meshes.ipynb","timestamp":1691543994096}]},"disseminate_notebook_info":{"backup_notebook_id":"569222367081034"},"kernelspec":{"display_name":"pytorch3d_etc (local)","language":"python","name":"pytorch3d_etc_local"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5+"},"widgets":{"application/vnd.jupyter.widget-state+json":{"80833380f63c4e668d26045f397fa207":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ac86f89c4454458bf9f14b31b668837","IPY_MODEL_54ecc7c72cc1471fab891a9522d072c1","IPY_MODEL_09504b9761304f22a983b9d84e1a3381"],"layout":"IPY_MODEL_16952c39face4d17a07e2b406efa7e5f"}},"2ac86f89c4454458bf9f14b31b668837":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4087164151264becb9b9966819a5f814","placeholder":"​","style":"IPY_MODEL_c21d1835af464a9d86b26f0c9cd08454","value":"  0%"}},"54ecc7c72cc1471fab891a9522d072c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_5876606f717e4e2b871befb181e2504e","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7baef410ff5481da512fcd10b38b470","value":0}},"09504b9761304f22a983b9d84e1a3381":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de68737312f143be9f1786f3e43ca4fc","placeholder":"​","style":"IPY_MODEL_492669478b444403af3bbcad2e2e0818","value":" 0/100 [00:00&lt;?, ?it/s]"}},"16952c39face4d17a07e2b406efa7e5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4087164151264becb9b9966819a5f814":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c21d1835af464a9d86b26f0c9cd08454":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5876606f717e4e2b871befb181e2504e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7baef410ff5481da512fcd10b38b470":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de68737312f143be9f1786f3e43ca4fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"492669478b444403af3bbcad2e2e0818":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}